{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e840586",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "data= pd.read_csv(r\"C:\\Users\\Lenovo\\Documents\\Ironhack\\DATA\\caste_expenditure_durable.csv\")\n",
    "#We make a copy of the file and work on it\n",
    "data = data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing (data):\n",
    "    missing_number = data.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (gdata.isnull().sum()/gender.isnull().count()).sort_values(ascending=False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n",
    "    return missing_values\n",
    "\n",
    "missing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce140692",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ae0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME VALUE IN COLUM\n",
    "data3['Item Code']=data3['Item Code'].replace(to_replace=r'sub-total[^|]*$', value='', regex=True)\n",
    "data3['Item Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80804a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME VALUE IN COLUM - other method\n",
    "data3['Item Code'] = data['Item Code'].str.replace(r'kitchen equipment[^|]*$', 'kitchen equipment', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME VALUE IN COLUM -other method \n",
    "data3['Item Code']=data3['Item Code'].replace(to_replace=r'[:]', value='', regex=True) #data3['Item Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME VALUE IN COLUM\n",
    "data3['Item Code']=data3['Item Code'].replace(to_replace=r': ', value='_365days', regex=True)\n",
    "data3['Item Code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63804b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column \"a\" of a DataFrame\n",
    "df[\"a\"] = pd.to_numeric(df[\"a\"], errors='coerce')\n",
    "\n",
    "# convert all columns of DataFrame\n",
    "df = df.apply(pd.to_numeric) # convert all columns of DataFrame\n",
    "\n",
    "# convert just columns \"a\" and \"b\"\n",
    "df[[\"a\", \"b\"]] = df[[\"a\", \"b\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aad1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime column to datetime format\n",
    "data['Date/Time'] = pd.to_datetime(data['Date/Time'])\n",
    "\n",
    "# add hour and weekday columns to my dataframe\n",
    "data['Hour'] = data['Date/Time'].dt.hour\n",
    "data['Weekday'] = data['Date/Time'].dt.day_name()\n",
    "\n",
    "# check datapoints distribution by weekdays\n",
    "sns.countplot(x='Weekday', data=data, color='black')\n",
    "plt.show()\n",
    "\n",
    "# check datapoints distribution by hour\n",
    "sns.histplot(data=data, x='Hour', color='black', bins=10)\n",
    "plt.show()\n",
    "\n",
    "#CONCAT COLONNE DATE TIME\n",
    "df['datetime'] = pd.to_datetime(df.Date + ' '+ df.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d00829",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.col.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.col.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nameDest.nunique()\n",
    "(data.nameDest.nunique()/data.shape[0])*100 #If too much value unique, we drop\n",
    "data.drop(columns=['nameOrig', 'nameDest'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de valeur dans chaque colonne\n",
    "for col in ['patient_gender', 'doctor_name', 'prescribed_medicines', 'diagnosis']:\n",
    "    print(data[col].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd889aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer valeur en 0 et 1 6 SORTE DE ENCODING\n",
    "data['diagnosis_int']= np.where(data['diagnosis']=='no diagnosis', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dedd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for duplicates\n",
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample\n",
    "data_encoder = data_encoder.sample(frac=.1, axis=0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "data.drop('col', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baccd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO CHECK THE LABELS in Y\n",
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00280cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers: \n",
    "data.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7deaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do drop outliers\n",
    "data = data.drop(data[data['col'] >40].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlations :heatmap\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data.corr(), annot=True, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc52b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfonction de la heat map, prendre les plus forte correlation avec y ( derniere variable)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "sns.regplot(data.colx1, data.coly, ax=ax1)\n",
    "sns.regplot(data.colx2, data.coly, ax=ax2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#si ligne lineaire avec la droite - correlation positive, si vers la gauble, correlation lineaire negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autre graphique possible\n",
    "plt.scatter(data.colx, data.coly)\n",
    "\n",
    "#for array:\n",
    "plt.scatter(x[:, 0], x[:, 1], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column/ Group colum in one\n",
    "beverage = ['Hot chocolate', 'Coffee', 'Tea', 'Mineral water', 'Juice', 'Coke', 'Smoothies']\n",
    "other = ['NONE', 'Christmas common', 'Gift voucher', \"Valentine's card\", 'Tshirt', 'Afternoon with the baker', 'Postcard', 'Siblings', 'Nomad bag', 'Adjustment', 'Drinking chocolate spoons ', 'Coffee granules ']\n",
    "kids = [\"Ella's Kitchen Pouches\", 'My-5 Fruit Shoot', 'Kids biscuit']\n",
    "snacks = ['Mighty Protein', 'Pick and Mix Bowls', 'Caramel bites', 'Bare Popcorn', 'Crisps', 'Cherry me Dried fruit', 'Raw bars']\n",
    "bread = ['Bread', 'Toast', 'Baguette', 'Focaccia', 'Scandinavian']\n",
    "breakfast_pastry = ['Muffin', 'Pastry', 'Medialuna', 'Scone']\n",
    "dessert = ['Cookies', 'Tartine', 'Fudge', 'Victorian Sponge', 'Cake', 'Alfajores', 'Brownie', 'Bread Pudding', 'Bakewell', 'Raspberry shortbread sandwich', 'Lemon and coconut', 'Crepes', 'Chocolates', 'Truffles', 'Panatone']\n",
    "condiments = ['Jam', 'Dulce de Leche', 'Honey', 'Gingerbread syrup', 'Extra Salami or Feta', 'Bacon', 'Spread', 'Chimichurri Oil']\n",
    "breakfast = ['Eggs', 'Frittata', 'Granola', 'Muesli', 'Duck egg', 'Brioche and salami']\n",
    "lunch = ['Soup', 'Sandwich', 'Chicken sand', 'Salad', 'Chicken Stew']\n",
    "other_food = [x for x in df.Item.unique() if x not in beverage \n",
    "                and x not in other and x not in kids and x not in snacks \n",
    "                and x not in bread and x not in breakfast_pastry \n",
    "                and x not in dessert and x not in condiments \n",
    "                and x not in breakfast and x not in lunch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ee03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns binaire: 1 or 0 / yes/no\n",
    "df['beverage'] = df.Item.isin(beverage).astype(int) #if berevage = 0, if not 1/ whick class of good was bought\n",
    "df['other'] = df.Item.isin(other).astype(int)\n",
    "df['kids'] = df.Item.isin(kids).astype(int)\n",
    "df['snacks'] = df.Item.isin(snacks).astype(int)\n",
    "df['bread'] = df.Item.isin(bread).astype(int)\n",
    "df['breakfast_pastry'] = df.Item.isin(breakfast_pastry).astype(int)\n",
    "df['breakfast'] = df.Item.isin(breakfast).astype(int)\n",
    "df['dessert'] = df.Item.isin(dessert).astype(int)\n",
    "df['condiments'] = df.Item.isin(condiments).astype(int)\n",
    "df['lunch'] = df.Item.isin(lunch).astype(int)\n",
    "df['other_food'] = df.Item.isin(other_food).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby - par deux\n",
    "data2 = data.groupby(['Transaction','datetime']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforme index en columns\n",
    "data.reset_index(level='datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d362b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforme dtypes en date\n",
    "data.col = pd.to_datetime(data['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5876a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATION colonne en heur ( heure de la journ√©e) et en jour ( de la semaine)\n",
    "data['hour']=data['datetime'].dt.hour\n",
    "data['weekday']=data['datetime'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation en data frame \n",
    "df_pca = pd.DataFrame(df_pca, columns = ['PC'+str(i) for i in range(1,6)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67974000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colonne et creation de noms en boucle\n",
    " columns = ['PC'+str(i) for i in range(1,6)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d659489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nouvelle dataframe, avec colonnes\n",
    "items = df[['Transaction', 'Item']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nouvelle dataframe, avec une seule colonnes - reset index sinon serie\n",
    "clusters = df_group['cluster'].reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba577f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge deux dataframe, avec une key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding - object columns et booleans columns\n",
    "# Encode the labels into unique integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for i in df.columns:\n",
    "    if df[i].dtypes == \"object\":\n",
    "         df[i] = encoder.fit_transform(df[i])\n",
    "    if df[i].dtypes == \"bool\":\n",
    "         df[i] = encoder.fit_transform(df[i])\n",
    "\n",
    "\n",
    "df['class'] = encoder.fit_transform(df['class'] )\n",
    "df['embarked'] = encoder.fit_transform(df['embarked'] )\n",
    "df['deck'] = encoder.fit_transform(df['deck'] )\n",
    "df['age'] = encoder.fit_transform(df['age'] )\n",
    "\n",
    "for col in file_clean.columns[5:]:\n",
    "    print(col)\n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "\n",
    "for col in data.columns[5:]:\n",
    "    data[col] = label.fit_transform(data[col])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
